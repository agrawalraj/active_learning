{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset to use - change this value to analyze a different data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'chain_test5'\n",
    "nnodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis import check_folder\n",
    "check_folder.check_folder(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def order_tpr_fpr(fprs, tprs):\n",
    "    df = pd.DataFrame(dict(fpr=fprs, tpr=tprs))\n",
    "    df.sort_values('fpr', ascending=False)\n",
    "    df.drop_duplicates(subset='fpr', keep='last', inplace=True)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "a = order_tpr_fpr([.2, .1, .2], [.3, .2, .4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in parent probabilities and rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import check_gies, check_samples\n",
    "import numpy as np\n",
    "import itertools as itr\n",
    "from collections import defaultdict\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import causaldag as cd\n",
    "from utils import graph_utils\n",
    "from scipy.special import logsumexp\n",
    "IV_STRENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arc_probs(nnodes, dags):\n",
    "    poss_arcs = set(itr.permutations(range(nnodes), 2))\n",
    "    counts = {arc: 0 for arc in poss_arcs}\n",
    "    for dag in dags:\n",
    "        for arc in dag.arcs:\n",
    "            counts[arc] += 1\n",
    "    return {arc: count/len(dags) for arc, count in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_score_full(arc_probs, true_dag):\n",
    "    possible_arcs = set(itr.permutations(true_dag.nodes, 2))\n",
    "    nonarcs = possible_arcs - true_dag.arcs\n",
    "    return sum(1-arc_probs[arc] for arc in true_dag.arcs) + sum(arc_probs[nonarc] for nonarc in nonarcs)\n",
    "\n",
    "\n",
    "def l1_score_fp_full(arc_probs, true_dag):\n",
    "    possible_arcs = set(itr.permutations(true_dag.nodes, 2))\n",
    "    nonarcs = possible_arcs - true_dag.arcs\n",
    "    return sum(arc_probs[nonarc] for nonarc in nonarcs)\n",
    "\n",
    "\n",
    "def l1_score_fn_full(arc_probs, gdag):\n",
    "    return sum(1-arc_probs[arc] for arc in true_dag.arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_folders = check_gies.get_dag_folders(dataset)\n",
    "true_dags = check_gies.get_true_dags(dag_folders)\n",
    "covs = [d.covariance for d in true_dags]\n",
    "true_dags_barren = [cd.DAG(set(dag.nodes), dag.arcs) for dag in true_dags]\n",
    "true_mecs_barren = [[cd.DAG(true_dag.nodes, arcs) for arcs in true_dag.cpdag().all_dags()] for true_dag in true_dags_barren]\n",
    "true_mecs = [[graph_utils.cov2dag(cov, d) for d in mec] for mec, cov in zip(true_mecs_barren, covs)]\n",
    "ndags = len(true_dags)\n",
    "\n",
    "strategy_names = ['entropy-dag-collection', 'random']\n",
    "ks = [1]\n",
    "bs = [1]\n",
    "ns = [2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_by_dag = [\n",
    "    [\n",
    "        cd.BinaryIntervention(\n",
    "            intervention1=cd.ConstantIntervention(val=-IV_STRENGTH*std),\n",
    "            intervention2=cd.ConstantIntervention(val=IV_STRENGTH*std),\n",
    "        ) for std in np.diag(true_dag.covariance)**.5\n",
    "    ]\n",
    "    for true_dag in true_dags\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec_posteriors = []\n",
    "for true_dag, true_mec in zip(true_dags, true_mecs):\n",
    "    da = xr.DataArray(\n",
    "        np.zeros([len(true_mec), len(strategy_names), len(ns), len(bs), len(ks)]),\n",
    "        dims=['mec_member', 'strategy', 'n', 'b', 'k'],\n",
    "        coords={\n",
    "            'mec_member': list(range(len(true_mec))),\n",
    "            'strategy': strategy_names,\n",
    "            'n': ns,\n",
    "            'b': bs,\n",
    "            'k': ks\n",
    "        }\n",
    "    )\n",
    "    mec_posteriors.append(da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for dag_ix, dag_folder, true_dag, true_mec in tqdm(zip(range(ndags), dag_folders, true_dags, true_mecs), total=ndags):\n",
    "    for strat, n, b, k in itr.product(strategy_names, ns, bs, ks):\n",
    "        strat_str = '%s,n=%s,b=%s,k=%s' % (strat, n, b, k)\n",
    "        log_posteriors = np.zeros(len(true_mec))\n",
    "        \n",
    "        # == calculate log posteriors based on interventional data\n",
    "        for iv_node in list(range(nnodes)) + [-1]:\n",
    "            intervention_fn = os.path.join(dag_folder, strat_str, 'samples', 'intervention=%d.csv' % iv_node)\n",
    "            if sum(1 for line in open(intervention_fn)) != 0:\n",
    "                samples = np.loadtxt(intervention_fn)\n",
    "                for mec_ix, mec_member in enumerate(true_mec):\n",
    "                    if iv_node == -1:\n",
    "                        logpdfs = mec_member.logpdf(samples)\n",
    "                    else:\n",
    "                        logpdfs = mec_member.logpdf(samples, {iv_node: interventions_by_dag[dag_ix][iv_node]})\n",
    "                    log_posteriors[mec_ix] += logpdfs.sum()\n",
    "        \n",
    "        posteriors = np.exp(log_posteriors - logsumexp(log_posteriors))\n",
    "        if not np.isclose(posteriors.sum(), 1):\n",
    "            raise ValueError\n",
    "        mec_posteriors[dag_ix].loc[dict(strategy=strat, n=n, b=b, k=k)] = posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_error_da = xr.DataArray(\n",
    "    np.zeros([len(true_dags), len(strategy_names), len(ns), len(bs), len(ks)]),\n",
    "    dims=['dag', 'strategy', 'n', 'b', 'k'],\n",
    "    coords={\n",
    "        'dag': list(range(len(true_dags))),\n",
    "        'strategy': strategy_names,\n",
    "        'n': ns,\n",
    "        'b': bs,\n",
    "        'k': ks\n",
    "    }\n",
    ")\n",
    "for dag_ix, true_dag, true_mec in zip(range(len(true_dags)), true_dags, true_mecs):\n",
    "    for strat, n, b, k in itr.product(strategy_names, ns, bs, ks):\n",
    "        posteriors = mec_posteriors[dag_ix].loc[dict(strategy=strat, n=n, b=b, k=k)]\n",
    "        ntrue = 0\n",
    "        for mec_member, posterior in zip(true_mec, posteriors):\n",
    "            if mec_member.arcs == true_dag.arcs:\n",
    "                ntrue += 1\n",
    "                penalty = 1 - posterior\n",
    "            else:\n",
    "                penalty = posterior\n",
    "            l1_error_da.loc[dict(dag=dag_ix, strategy=strat, n=n, b=b, k=k)] += penalty\n",
    "        if ntrue != 1:\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (strategy: 2, n: 1, b: 1, k: 1)>\n",
       "array([[[[1.506667]]],\n",
       "\n",
       "\n",
       "       [[[1.713968]]]])\n",
       "Coordinates:\n",
       "  * strategy  (strategy) <U22 'entropy-dag-collection' 'random'\n",
       "  * n         (n) int64 2048\n",
       "  * b         (b) int64 1\n",
       "  * k         (k) int64 1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_error_da.mean('dag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, k, b in itr.product(ns, ks, bs):\n",
    "    print(n, k, b)\n",
    "    print(l1_scores_da.sel(n=n, k=k, b=b).mean(dim='dag').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(5))+[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_da = check_samples.count_samples(dataset, strategy_names, ks, bs, ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_da = check_gies.get_rates_data_array(\n",
    "    parent_probs_by_dag,\n",
    "    true_dags,\n",
    "    target=9,\n",
    "    strategy_names=strategy_names,\n",
    "    ks=ks,\n",
    "    bs=bs,\n",
    "    ns=ns,\n",
    "    alphas=np.linspace(0, 1, 11)\n",
    ")\n",
    "print(rates_da.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot curves for each strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] =(20,12)\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linestyles = ['solid', 'dashed', 'dotted']\n",
    "colors = sns.color_palette()\n",
    "sample_handles = [\n",
    "    mlines.Line2D([0], [0], color='k', linestyle=linestyle, label=n) \n",
    "    for n, linestyle in zip(ns, linestyles)\n",
    "]\n",
    "strat_handles = [\n",
    "    mpatches.Patch(facecolor=color, label=strat)\n",
    "    for strat, color in zip(strategy_names, colors)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "rate_avgs_da = rates_da.mean(dim='dag')\n",
    "b=1\n",
    "k=1\n",
    "for strategy, color in zip(strategy_names, colors):\n",
    "    for n, linestyle in zip(ns, linestyles):\n",
    "        strat_avg_tprs = rate_avgs_da.sel(strategy=strategy, b=b, k=k, n=n, rate='tpr').values\n",
    "        strat_avg_fprs = rate_avgs_da.sel(strategy=strategy, b=b, k=k, n=n, rate='fpr').values\n",
    "        tpr_fpr_df = order_tpr_fpr(strat_avg_fprs, strat_avg_tprs)\n",
    "        plt.plot(tpr_fpr_df['fpr'], tpr_fpr_df['tpr'], linestyle=linestyle, color=color)\n",
    "\n",
    "plt.legend(\n",
    "    handles=strat_handles + sample_handles\n",
    ")\n",
    "plt.title(dataset + ', batches=%s, k=%s' % (b, k))\n",
    "plt.xlabel('Average FPR')\n",
    "plt.ylabel('Average TPR');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(bs), len(ns), sharey=True, sharex=True)\n",
    "k=1\n",
    "for (b_ix, b), (n_ix, n) in itr.product(list(enumerate(bs)), list(enumerate(ns))):\n",
    "    for strategy, color in zip(strategy_names, colors):\n",
    "        avg_rates = rate_avgs_da.sel(strategy=strategy, b=b, k=k, n=n)\n",
    "        tpr_fpr_df = order_tpr_fpr(avg_rates.sel(rate='fpr').values, avg_rates.sel(rate='tpr').values)\n",
    "        ax[b_ix, n_ix].plot(tpr_fpr_df['fpr'], tpr_fpr_df['tpr'], color=color)\n",
    "        if b_ix == len(bs)-1:\n",
    "            ax[b_ix, n_ix].set_xlabel('n = %s' % n)\n",
    "        if n_ix == 0:\n",
    "            ax[b_ix, n_ix].set_ylabel('b = %s' % b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256\n",
    "k = 2\n",
    "b = 2\n",
    "\n",
    "c_e = counts_da.sel(strategy='entropy', k=k, b=b, n=n)/n\n",
    "c_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_r = counts_da.sel(strategy='random', k=k, b=b, n=n)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_e = entropy(c_e.T)\n",
    "ent_r = entropy(c_r.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_e.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def random_choices(p, k):\n",
    "    c = Counter(random.choices(list(range(p)), k=k))\n",
    "    arr = np.zeros(p)\n",
    "    for i, val in c.items():\n",
    "        arr[i] += val\n",
    "    return arr/arr.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [20, 40, 100, 200]:\n",
    "    print(entropy(random_choices(20, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy([.5, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_da.sel(strategy='entropy', k=1, b=1, n=256, dag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_da.sel(strategy='random', k=2, b=2, n=256, dag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
